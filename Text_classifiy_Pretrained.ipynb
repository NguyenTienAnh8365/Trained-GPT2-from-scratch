{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a4e89f",
   "metadata": {
    "id": "51a4e89f"
   },
   "source": [
    "## **Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f62eb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 12709,
     "status": "ok",
     "timestamp": 1752567732784,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "72f62eb5",
    "outputId": "7a1b4fc5-5bc7-4756-ee96-5a506fc1696d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.0.0 fsspec-2025.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa4357a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345,
     "referenced_widgets": [
      "64d06335f3164659999361885e9144bb",
      "d0d072cf03de4b998903be18713e9282",
      "39a1031fa2f74b6d9ea6f91962c95dca",
      "d3f2a8c1b30a4cff93192c0b3961edab",
      "a839167f93fc467da73825734c5c09d2",
      "2c9cbd604e5b46ae8cda29727484e5f7",
      "724efe3f58b146ee9dcf78ea94c3d75d",
      "419a2c682efd4d868ecc258807e21bbc",
      "ae8df112c59044b384ef97d4e71e8745",
      "62317a9e7a8c4839a0d8bb50c6041a85",
      "4737d20845464363ad4eabb403838234",
      "fa1d3606252c41ae8866447fed50bc92",
      "7b340921b8854ab996f39f8bcde67fcb",
      "a2f7047a15df47488a1aa7c0e24be126",
      "7c4d3a395a724b029bbd68f82b33b6be",
      "6d0e9d28e40f4376ae426d657bd3c304",
      "66f8b9a446254aee90d0ce39a89f32d9",
      "3ba6c6b9b7eb4a66b3c09395e445b5f3",
      "bb0cc134f40f4961acda66a526d30ba5",
      "e2d427eb328149cf8105b274f7e90bdc",
      "ab6a26c6fff24a7fafed7c84c0bc771b",
      "9d440b3469f648e18be37f900363fee1",
      "79cb130c6b304aa5be379ce8616b867e",
      "63a24c58d15d4290b967cf8faf3f17f2",
      "03bd6a5dc5674c66b786fd97752d171e",
      "17bce47d80154747831dd0a6e1aee0e6",
      "7bca5ce40ec742348cd4b289c87a76c5",
      "997b9edf85af47aa9e423fd29ddc86b1",
      "a0a51766bfdd4a6d9059782b48f07ce2",
      "27c69066fb9541c89705b7483f799088",
      "dbb3fba0f17748449e99721127acd334",
      "7989da5b20df4bc4b59cd5c0883d44d3",
      "66eeefd76d564616beb1a601d88f41dd",
      "4c6cd9954ffb489e91996563f1c8297c",
      "fc8d290dab2a484b939612fdab98db31",
      "64ce6a7364344d97a604091f49a5b976",
      "fdf1a0596c634bbfb69f7565cd93107d",
      "57ad2f3558214c7ca8c503448582bee4",
      "670a2748b8f8431d9dd242b4a05972fc",
      "8262f8bf32ff40379debb0eb50c68847",
      "9d364f9fddaf4008a6798693a3639def",
      "50128ec33a504d90b243b8df6d1a7c4c",
      "21e01ca959184b4cba57c3a429d8364b",
      "343487ceb30744a0806c621cecfd675e",
      "5065d833733a4419aeb9889116a1c858",
      "6d8caec09bb6434fb913336e134ffd26",
      "a7a75cc849ee4afcb5a94bf51186d07d",
      "0fd44b1600f845d68e249613301c0ac0",
      "8ca5c0827a57417fa3060ff6ee757dc8",
      "7e779cc4911c427784a266b6c051de90",
      "17e0acf41e784dbeb693655129b9f625",
      "50e6be8b0b124a059946ae51595a63ae",
      "8136e8507ddc4009be8cd53777dd2804",
      "fdb955f4546f47078c3edf56455a120e",
      "04c9e10e27204784af0675524f4dd8eb",
      "8edc7efd4226403e9fbdcdc938a4a972",
      "06b3836d68744895a86b55f1dfb7d100",
      "0896e20a027840188b587fd7b6f9aebc",
      "f95b98ab30404b22951e29d9f6d131ef",
      "ac660810215f491d878c05886b5d74e8",
      "6d9e525a15a0401b96e65b4af8b8af00",
      "25235fc516b14993b4abc7debb44ffea",
      "1f6c99eaa5ae4265a06c1e27e4957c97",
      "eecd4b2f3e7e47b18f5b342359fd730a",
      "849b3e37044a42dc9dc45239a290fcf1",
      "a3e02cb670bd4af186e1a999a2d6f82b",
      "181f4760bae8484a82a734f3726238b2",
      "b2a5ccf9a8a94433a822eef4419eeb51",
      "b2c6b374d0b0415e92b45d0a061d0842",
      "ef9438f3819b4e15b0d6b08b77ce5460",
      "e0728738789943fba338f8f513c998f1",
      "bc4cb23c703d497d85475002164169cd",
      "a47f797fa3d04c2f97c60cdba61a727a",
      "85fb30e3a7f14c98be99c982916c6648",
      "72ca8156851e4e2786c1ac24f5090466",
      "d4ca51f5223b46809af368fc9cda3422",
      "dd6a05292a25452ba450c14370c97803"
     ]
    },
    "executionInfo": {
     "elapsed": 9909,
     "status": "ok",
     "timestamp": 1752567742697,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "5fa4357a",
    "outputId": "7f26d0a5-e8cd-450f-fe45-30787140c1f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d06335f3164659999361885e9144bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1d3606252c41ae8866447fed50bc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cb130c6b304aa5be379ce8616b867e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6cd9954ffb489e91996563f1c8297c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5065d833733a4419aeb9889116a1c858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edc7efd4226403e9fbdcdc938a4a972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181f4760bae8484a82a734f3726238b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a3c2f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1752567742756,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "e2a3c2f0",
    "outputId": "8629b5dd-c816-414d-deba-4b1dbf5dab42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3189e5",
   "metadata": {
    "id": "bc3189e5"
   },
   "source": [
    "## **Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c721f9cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "65e0125f4db648908cb6be4220e02c1d",
      "824f3afc97034da0b0501aeaff4ec4a0",
      "1c882af3a7134f9a90c3cb71ffd7b4dd",
      "5b0df3899e4342fd92e4f006428ba75c",
      "a0f697dafb854a41a0ea66ee9981be33",
      "7d3e8db38bcf48fc91655b3eff75b503",
      "0e288b8a64924581b60c6dccafb8f9c3",
      "fa83494a89224b3b9e5b10214d351640",
      "03306547d6d043d09bf7d320c3f1e029",
      "2e93da83c17a4f72aa3e94b2c40e8901",
      "d0a3edc958a04850881b8a9303d4e5be",
      "ab32656c8afb4cfeab47b3489b5ca164",
      "11c61ca13e764ff7a102fd0ed46efcbc",
      "2b1ad25791014e1681029e5ac081ddf0",
      "2f6e952b8c5b4cb8aac950231ef3a3b3",
      "874ed5a0754540c1bb5196ca4686c7b2",
      "10dd4a246fbf4c3ca05942aeaaeb3eda",
      "1929d7b5308b4baf917606e393aa7839",
      "c15073ca9a564769943b21bf02f9b587",
      "67e3ed9a9208415a832d1234fe8875e4",
      "d47bda4d98604e3b8ae4cfd622c28e3f",
      "c22526cb27e544e29621dd728b0c3c80",
      "6242839437434925b729a32fa5d71bd9",
      "41212ce9df97495fb022901d0b9b8fd3",
      "0148757656e540cb82f498a0c75082ad",
      "7ce61860f286491fa45db6fe72368296",
      "a080025ed83a40eba0edcafe0d50dc11",
      "ef01da2463034cb6be5c0f73d7cfe87f",
      "7d3ac2583cd94e3eb4279d1f94008735",
      "02c55c19694b44abbcbe4e0f70542867",
      "2fd104030bea4f109a2a4b5b612ff407",
      "2f3cafd306244d7eb64c77493941b15b",
      "9f1a9c83535d42deb6383bd7542baa9d"
     ]
    },
    "executionInfo": {
     "elapsed": 14913,
     "status": "ok",
     "timestamp": 1752567795180,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "c721f9cd",
    "outputId": "e5e03f8f-ae07-4a8f-ad18-786316f52c6e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e0125f4db648908cb6be4220e02c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab32656c8afb4cfeab47b3489b5ca164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6242839437434925b729a32fa5d71bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/692 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"NTA1802/Trained-GPT2-from-scratch\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5898ac1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "f0af793d23bb4e87812f5ba98e635ecf",
      "e342f22cbd7c4edbaec799b715de703a",
      "8b7b6eb478be4b3a9fc00333afed20b0",
      "2a67a8e4f18e4796b65e859c7a656c67",
      "fd46271900f740a3974a33907641c881",
      "5128787a211f461f96fded50ca3410f3",
      "a7808d91473149ccbc21386b5c4b63f5",
      "377c4c75d1b04338a3f909ccbd00c7e9",
      "f110093aa1b044ba90ee073b36e3e3b8",
      "fb25239ad8f7494fa0954b5ddba5e3f8",
      "c707243a631c4df99c311965c112d028",
      "57d85fcfb195402e92163873f19f99d9",
      "68da9f614ab84f089fb42c5057a5d2b3",
      "9cd8993fa9bc41a68203734962261448",
      "40eb5a2eed1b4763be50029346b19918",
      "e7107e5e55d246909fd131e739987fef",
      "1839270502104981a6bd81721cd2bca1",
      "798a97b887af4760800cefa168939fd0",
      "d9bf8b542bee4bdcade5489329f43224",
      "0b5ba9adc7424acbaade69c74b6ee11b",
      "45fa9603444c45d5aedabd37c6f55a36",
      "efb8837ba7d34708a39ed86a916ffe4c",
      "df49055d13284f5da6196c3beacf143c",
      "3d7204c843254797bca978abda818cd8",
      "37d3dc48dab5457284beea7c895d2daf",
      "0669d2cbd10b4187a50c12074d370fe7",
      "282db739f6d64b42ad2fd0f2d2d576ad",
      "e181fc3d8f0d42d7a0cac943dd2f9dff",
      "1cf70b301ad2438095f2e869190b5045",
      "e0a57f30ebc64bdebe53d18ee3e3969b",
      "61090d1b60c74445ba48da7c347bf57a",
      "329235abcade4d76a5ed7c8db07299a2",
      "436bf6e4ffde40aab9bf264cffd1ea57"
     ]
    },
    "executionInfo": {
     "elapsed": 106211,
     "status": "ok",
     "timestamp": 1752567901426,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "c5898ac1",
    "outputId": "569217c5-980b-42b3-e293-51f3843a776e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0af793d23bb4e87812f5ba98e635ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d85fcfb195402e92163873f19f99d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df49055d13284f5da6196c3beacf143c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec31daa7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1752567907504,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "ec31daa7",
    "outputId": "c10c2fa8-28d1-443e-9564-172bad6e0758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d63ea4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752567913810,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "f9d63ea4",
    "outputId": "07fd5cf8-48da-477e-e59f-781aa5cc9d6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ed01d",
   "metadata": {
    "id": "6e1ed01d"
   },
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb19611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "8c84238ad788421ab37bac05b0cdd502",
      "5260aef1738247b49d3a014455dfadc4",
      "e204c5ca5bac4c5bbcdee1ddd9cdf035",
      "f59b99a1e1494fc88e488e0b692d1d07",
      "e5a88100130f4400bd1334e7e170f610",
      "08f1f0ebf1f54902889bbefba12b1c9c",
      "fd64e51f9d43449cb84b065b75f01840",
      "cb2a66dffbea41caae5b58c3e80646cb",
      "f69b69b67305409d86cbed5a958e59e4",
      "f0f6963c5f2d43c4b4e4641bcd4fb382",
      "674861ee20414f1c8d9729175f785d05",
      "1abb1e4be35a40fb85d341c34b8ba728",
      "16e2efb6cdff4789be551216a11f0cfd",
      "b362eb5ee6894bf7a9fb27e837ecf1cb",
      "56a896cdd3c749d39ebeb53c477b9b09",
      "d0cc1a880f434dfda6978b43b1afc3ed",
      "b4d3123196f74a8a93177ea542888734",
      "0330d8ef34f543c48a7fd7e9f3006fcd",
      "8ab74fc6f9d944ac825c4dc960279893",
      "f9d8852512ae478f8248f37d8ff21f28",
      "af70257313bb4a9a8ca2db5f8bec55d8",
      "e41fa21a570e4be494e2d15ddfd63913"
     ]
    },
    "executionInfo": {
     "elapsed": 5867,
     "status": "ok",
     "timestamp": 1752567923869,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "6bb19611",
    "outputId": "b29a5204-3266-4400-9a6a-a756c195f1d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c84238ad788421ab37bac05b0cdd502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/756 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abb1e4be35a40fb85d341c34b8ba728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/39.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at NTA1802/Trained-GPT2-from-scratch and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load model with pre-trained weights and override num_labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: 'Negative', 1: 'Positive'},\n",
    "    label2id={'Negative': 0, 'Positive': 1}\n",
    ")\n",
    "\n",
    "# Thiết lập pad_token_id nếu cần\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496b815d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752567930789,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "496b815d",
    "outputId": "b68dc20f-e65f-4118-8963-f94b70da9eba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(20000, 256)\n",
       "    (wpe): Embedding(256, 256)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=768, nx=256)\n",
       "          (c_proj): Conv1D(nf=256, nx=256)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=1024, nx=256)\n",
       "          (c_proj): Conv1D(nf=256, nx=1024)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=256, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352136a",
   "metadata": {
    "id": "c352136a"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c58b9ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5239,
     "status": "ok",
     "timestamp": 1752567940297,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "7c58b9ad",
    "outputId": "0a327e8a-6d71-4763-c2d9-04a09849c761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5700a7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c65a33342ba94f4788f6ade5ff64a198",
      "65dcb2c713294fcd8b2933433cbecc9c",
      "186e82f3c6d54fe981daf0af94622b31",
      "1bca32fff7074853a840ffc88f8de4d0",
      "7c4d7c4cd7a4466ca5dc79c336edc9ed",
      "3f00cb9c14fb44f980dd70712fc086cc",
      "35100f06f87e41ff93b9746d486b20ad",
      "408ead0194924dc7a0264c5070d9b57d",
      "c0fa25a5565e4089a39ea363e7ef47cb",
      "4a43bd1bda0249059146957cc697ec76",
      "ed4e34afed1a4115b24a1e54ef958bf9"
     ]
    },
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1752567943799,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "d5700a7c",
    "outputId": "d89014ad-35eb-49ee-b737-4d2d06cbfafb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65a33342ba94f4788f6ade5ff64a198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673613c9",
   "metadata": {
    "executionInfo": {
     "elapsed": 2405,
     "status": "ok",
     "timestamp": 1752567953736,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "673613c9"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"imdb2-small-gpt2-small\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48843b4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "executionInfo": {
     "elapsed": 930846,
     "status": "ok",
     "timestamp": 1752568888152,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "48843b4a",
    "outputId": "d49a84ee-bd04-46c6-8293-9aaf4ca51df8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manhnguyentien8365\u001b[0m (\u001b[33manhnguyentien8365-no\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250715_082624-4erv57bd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anhnguyentien8365-no/huggingface/runs/4erv57bd' target=\"_blank\">imdb2-small-gpt2-small</a></strong> to <a href='https://wandb.ai/anhnguyentien8365-no/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anhnguyentien8365-no/huggingface' target=\"_blank\">https://wandb.ai/anhnguyentien8365-no/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anhnguyentien8365-no/huggingface/runs/4erv57bd' target=\"_blank\">https://wandb.ai/anhnguyentien8365-no/huggingface/runs/4erv57bd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 15:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.361780</td>\n",
       "      <td>0.840560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>0.386798</td>\n",
       "      <td>0.828120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.335154</td>\n",
       "      <td>0.858320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.368699</td>\n",
       "      <td>0.855160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.367199</td>\n",
       "      <td>0.859760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.407478</td>\n",
       "      <td>0.862120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.460502</td>\n",
       "      <td>0.855720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.543881</td>\n",
       "      <td>0.852680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.603121</td>\n",
       "      <td>0.847040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.588938</td>\n",
       "      <td>0.852200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1960, training_loss=0.19689403164143465, metrics={'train_runtime': 923.4411, 'train_samples_per_second': 270.727, 'train_steps_per_second': 2.122, 'total_flos': 1820000256000000.0, 'train_loss': 0.19689403164143465, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eGDlqPDBAZ6I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758,
     "referenced_widgets": [
      "bc88166f37d3441b9fc45a77a352d7ab",
      "a19e9a7de4164027b575a6e9b724fd94",
      "94edda9294db47eebbafed4d82d87d23",
      "14c5410249ee422fb91c0a44775e68f0",
      "9c1ac1047b884da89c11d14ffcc92662",
      "57ff869f8edc4b1fbc7305ace8cca9ff",
      "81345b6defd545beac0c06f99aad01f7",
      "86412752be174c568c6116dfb2d317b6",
      "b8049ea81c32406eaeca73df2489b40c",
      "93fd13e661a6448a9b523505002a71dd",
      "7fabede8677c46369e4a0ce7fc12fe5e",
      "0e99c8e61e4240f6bc3fa15f434ab9db",
      "e6b0b8b092864f26a46ac47892bac6d2",
      "de863c0f58c044eabe571654806a48f8",
      "10f03cd214d2485c819b43990b85fbb1",
      "e5f041a0776a4a85bf0832d331214176",
      "b0ec63967beb4f1595c08f1aa402d57a",
      "2d4a8199de9c42ab8019284d322d5b34",
      "8ae1a04b370c4465816177f5de56769e",
      "83e446736948450c9532d09700bb3182",
      "c751a79e54ba4de791854816ccd0701a",
      "3cac242fcc0c4204be57149ccbbfb52e"
     ]
    },
    "executionInfo": {
     "elapsed": 24435,
     "status": "ok",
     "timestamp": 1752568936976,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "eGDlqPDBAZ6I",
    "outputId": "146d694b-f380-440b-b3a2-200f1b437554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.7.9)\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): \n",
      "Add token as git credential? (Y/n) Y\n",
      "Token is valid (permission: write).\n",
      "The token `NTA1802/Pretrained-GPT2-Classification` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `NTA1802/Pretrained-GPT2-Classification`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc88166f37d3441b9fc45a77a352d7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/39.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e99c8e61e4240f6bc3fa15f434ab9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/NTA1802/Pretrained-GPT2-Classification/commit/8188c94036d1abe4569923f28b4c0f0f4acee264', commit_message='Upload tokenizer', commit_description='', oid='8188c94036d1abe4569923f28b4c0f0f4acee264', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NTA1802/Pretrained-GPT2-Classification', endpoint='https://huggingface.co', repo_type='model', repo_id='NTA1802/Pretrained-GPT2-Classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!huggingface-cli login\n",
    "\n",
    "\n",
    "model.push_to_hub(\"NTA1802/Pretrained-GPT2-Classification\")\n",
    "tokenizer.push_to_hub(\"NTA1802/Pretrained-GPT2-Classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1523f2",
   "metadata": {},
   "source": [
    "## **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd4c664",
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1752569004508,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "4cd4c664"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model_path = \"NTA1802/Pretrained-GPT2-Classification\" # Replace with your model path if different\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Ensure pad_token_id is set for the tokenizer\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def classify_text(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted class (0 or 1)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    # Map the class ID to the label (Negative or Positive)\n",
    "    predicted_label = model.config.id2label[predicted_class_id]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eabbc7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1752569276660,
     "user": {
      "displayName": "Anh-cs3-8365 Nguyễn Tiến",
      "userId": "07872704871188704138"
     },
     "user_tz": -420
    },
    "id": "9eabbc7d",
    "outputId": "72844b9a-f94f-440a-8f0d-0c6ca5ce49a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is: Positive\n",
      "The sentiment of the text is: Negative\n"
     ]
    }
   ],
   "source": [
    "text_to_classify = \"You are a very interesting and funny person. I believe you can have many talents. You can do it, keep trying, your future will be very bright.\"\n",
    "prediction = classify_text(text_to_classify)\n",
    "print(f\"The sentiment of the text is: {prediction}\")\n",
    "\n",
    "text_to_classify_2 = \"This movie is unbelievable, it exceeded my imagination, I didn't expect it to be so unworthy of anticipation. It's really a bit disappointing because I spent a lot of money to experience it and it ended up not being very good.\"\n",
    "prediction_2 = classify_text(text_to_classify_2)\n",
    "print(f\"The sentiment of the text is: {prediction_2}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
