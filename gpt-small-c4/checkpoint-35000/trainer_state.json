{
  "best_global_step": 35000,
  "best_metric": 4.832523345947266,
  "best_model_checkpoint": "/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt-small-c4/checkpoint-35000",
  "epoch": 9.828699803426003,
  "eval_steps": 1000,
  "global_step": 35000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2808199943836001,
      "grad_norm": 0.6986721158027649,
      "learning_rate": 4.859730412805392e-05,
      "loss": 7.2707,
      "step": 1000
    },
    {
      "epoch": 0.2808199943836001,
      "eval_loss": 6.605732440948486,
      "eval_runtime": 41.0811,
      "eval_samples_per_second": 463.424,
      "eval_steps_per_second": 9.664,
      "step": 1000
    },
    {
      "epoch": 0.5616399887672002,
      "grad_norm": 0.9213369488716125,
      "learning_rate": 4.719320415613592e-05,
      "loss": 6.4287,
      "step": 2000
    },
    {
      "epoch": 0.5616399887672002,
      "eval_loss": 6.248655796051025,
      "eval_runtime": 42.6829,
      "eval_samples_per_second": 446.033,
      "eval_steps_per_second": 9.301,
      "step": 2000
    },
    {
      "epoch": 0.8424599831508003,
      "grad_norm": 1.2662131786346436,
      "learning_rate": 4.578910418421792e-05,
      "loss": 6.166,
      "step": 3000
    },
    {
      "epoch": 0.8424599831508003,
      "eval_loss": 6.034111022949219,
      "eval_runtime": 42.8757,
      "eval_samples_per_second": 444.028,
      "eval_steps_per_second": 9.259,
      "step": 3000
    },
    {
      "epoch": 1.1232799775344005,
      "grad_norm": 1.4098591804504395,
      "learning_rate": 4.438500421229992e-05,
      "loss": 5.9897,
      "step": 4000
    },
    {
      "epoch": 1.1232799775344005,
      "eval_loss": 5.881381988525391,
      "eval_runtime": 42.9118,
      "eval_samples_per_second": 443.654,
      "eval_steps_per_second": 9.252,
      "step": 4000
    },
    {
      "epoch": 1.4040999719180005,
      "grad_norm": 1.5123035907745361,
      "learning_rate": 4.298090424038192e-05,
      "loss": 5.8608,
      "step": 5000
    },
    {
      "epoch": 1.4040999719180005,
      "eval_loss": 5.765547275543213,
      "eval_runtime": 42.799,
      "eval_samples_per_second": 444.823,
      "eval_steps_per_second": 9.276,
      "step": 5000
    },
    {
      "epoch": 1.6849199663016008,
      "grad_norm": 1.4643473625183105,
      "learning_rate": 4.157680426846392e-05,
      "loss": 5.7586,
      "step": 6000
    },
    {
      "epoch": 1.6849199663016008,
      "eval_loss": 5.661931991577148,
      "eval_runtime": 42.6161,
      "eval_samples_per_second": 446.732,
      "eval_steps_per_second": 9.316,
      "step": 6000
    },
    {
      "epoch": 1.9657399606852008,
      "grad_norm": 1.5599727630615234,
      "learning_rate": 4.0174108396517834e-05,
      "loss": 5.6721,
      "step": 7000
    },
    {
      "epoch": 1.9657399606852008,
      "eval_loss": 5.577486038208008,
      "eval_runtime": 42.3305,
      "eval_samples_per_second": 449.747,
      "eval_steps_per_second": 9.379,
      "step": 7000
    },
    {
      "epoch": 2.246559955068801,
      "grad_norm": 1.5340659618377686,
      "learning_rate": 3.8770008424599834e-05,
      "loss": 5.5888,
      "step": 8000
    },
    {
      "epoch": 2.246559955068801,
      "eval_loss": 5.505171775817871,
      "eval_runtime": 42.6481,
      "eval_samples_per_second": 446.397,
      "eval_steps_per_second": 9.309,
      "step": 8000
    },
    {
      "epoch": 2.527379949452401,
      "grad_norm": 1.6983119249343872,
      "learning_rate": 3.736731255265375e-05,
      "loss": 5.5279,
      "step": 9000
    },
    {
      "epoch": 2.527379949452401,
      "eval_loss": 5.441108703613281,
      "eval_runtime": 42.2915,
      "eval_samples_per_second": 450.162,
      "eval_steps_per_second": 9.387,
      "step": 9000
    },
    {
      "epoch": 2.808199943836001,
      "grad_norm": 1.8253368139266968,
      "learning_rate": 3.596321258073575e-05,
      "loss": 5.468,
      "step": 10000
    },
    {
      "epoch": 2.808199943836001,
      "eval_loss": 5.384087085723877,
      "eval_runtime": 42.5907,
      "eval_samples_per_second": 446.999,
      "eval_steps_per_second": 9.321,
      "step": 10000
    },
    {
      "epoch": 3.089019938219601,
      "grad_norm": 1.9005451202392578,
      "learning_rate": 3.456051670878967e-05,
      "loss": 5.4142,
      "step": 11000
    },
    {
      "epoch": 3.089019938219601,
      "eval_loss": 5.331680774688721,
      "eval_runtime": 42.0335,
      "eval_samples_per_second": 452.925,
      "eval_steps_per_second": 9.445,
      "step": 11000
    },
    {
      "epoch": 3.3698399326032016,
      "grad_norm": 1.6727293729782104,
      "learning_rate": 3.315641673687167e-05,
      "loss": 5.3671,
      "step": 12000
    },
    {
      "epoch": 3.3698399326032016,
      "eval_loss": 5.283949851989746,
      "eval_runtime": 41.9839,
      "eval_samples_per_second": 453.46,
      "eval_steps_per_second": 9.456,
      "step": 12000
    },
    {
      "epoch": 3.650659926986801,
      "grad_norm": 1.9094890356063843,
      "learning_rate": 3.175231676495367e-05,
      "loss": 5.3229,
      "step": 13000
    },
    {
      "epoch": 3.650659926986801,
      "eval_loss": 5.242125988006592,
      "eval_runtime": 42.0278,
      "eval_samples_per_second": 452.986,
      "eval_steps_per_second": 9.446,
      "step": 13000
    },
    {
      "epoch": 3.9314799213704017,
      "grad_norm": 1.786813735961914,
      "learning_rate": 3.0349620893007585e-05,
      "loss": 5.2859,
      "step": 14000
    },
    {
      "epoch": 3.9314799213704017,
      "eval_loss": 5.2003703117370605,
      "eval_runtime": 42.1085,
      "eval_samples_per_second": 452.117,
      "eval_steps_per_second": 9.428,
      "step": 14000
    },
    {
      "epoch": 4.212299915754001,
      "grad_norm": 1.8887180089950562,
      "learning_rate": 2.894552092108958e-05,
      "loss": 5.2422,
      "step": 15000
    },
    {
      "epoch": 4.212299915754001,
      "eval_loss": 5.1610822677612305,
      "eval_runtime": 42.987,
      "eval_samples_per_second": 442.879,
      "eval_steps_per_second": 9.235,
      "step": 15000
    },
    {
      "epoch": 4.493119910137602,
      "grad_norm": 2.0221705436706543,
      "learning_rate": 2.75428250491435e-05,
      "loss": 5.2101,
      "step": 16000
    },
    {
      "epoch": 4.493119910137602,
      "eval_loss": 5.123721122741699,
      "eval_runtime": 44.2488,
      "eval_samples_per_second": 430.249,
      "eval_steps_per_second": 8.972,
      "step": 16000
    },
    {
      "epoch": 4.773939904521201,
      "grad_norm": 2.2417685985565186,
      "learning_rate": 2.61387250772255e-05,
      "loss": 5.1831,
      "step": 17000
    },
    {
      "epoch": 4.773939904521201,
      "eval_loss": 5.091982364654541,
      "eval_runtime": 43.3108,
      "eval_samples_per_second": 439.567,
      "eval_steps_per_second": 9.166,
      "step": 17000
    },
    {
      "epoch": 5.054759898904802,
      "grad_norm": 1.938607096672058,
      "learning_rate": 2.473602920527942e-05,
      "loss": 5.1508,
      "step": 18000
    },
    {
      "epoch": 5.054759898904802,
      "eval_loss": 5.0607805252075195,
      "eval_runtime": 41.6111,
      "eval_samples_per_second": 457.523,
      "eval_steps_per_second": 9.541,
      "step": 18000
    },
    {
      "epoch": 5.335579893288402,
      "grad_norm": 2.0534815788269043,
      "learning_rate": 2.3331929233361414e-05,
      "loss": 5.1182,
      "step": 19000
    },
    {
      "epoch": 5.335579893288402,
      "eval_loss": 5.031571865081787,
      "eval_runtime": 41.7083,
      "eval_samples_per_second": 456.456,
      "eval_steps_per_second": 9.518,
      "step": 19000
    },
    {
      "epoch": 5.616399887672002,
      "grad_norm": 2.119905710220337,
      "learning_rate": 2.1927829261443417e-05,
      "loss": 5.0975,
      "step": 20000
    },
    {
      "epoch": 5.616399887672002,
      "eval_loss": 5.003675937652588,
      "eval_runtime": 42.1028,
      "eval_samples_per_second": 452.179,
      "eval_steps_per_second": 9.429,
      "step": 20000
    },
    {
      "epoch": 5.8972198820556025,
      "grad_norm": 2.3703458309173584,
      "learning_rate": 2.0525133389497335e-05,
      "loss": 5.0787,
      "step": 21000
    },
    {
      "epoch": 5.8972198820556025,
      "eval_loss": 4.9814958572387695,
      "eval_runtime": 41.2614,
      "eval_samples_per_second": 461.399,
      "eval_steps_per_second": 9.622,
      "step": 21000
    },
    {
      "epoch": 6.178039876439202,
      "grad_norm": 2.0702271461486816,
      "learning_rate": 1.912103341757933e-05,
      "loss": 5.0493,
      "step": 22000
    },
    {
      "epoch": 6.178039876439202,
      "eval_loss": 4.959826469421387,
      "eval_runtime": 41.9842,
      "eval_samples_per_second": 453.457,
      "eval_steps_per_second": 9.456,
      "step": 22000
    },
    {
      "epoch": 6.458859870822803,
      "grad_norm": 2.1893138885498047,
      "learning_rate": 1.7716933445661333e-05,
      "loss": 5.0323,
      "step": 23000
    },
    {
      "epoch": 6.458859870822803,
      "eval_loss": 4.940311431884766,
      "eval_runtime": 53.0079,
      "eval_samples_per_second": 359.154,
      "eval_steps_per_second": 7.489,
      "step": 23000
    },
    {
      "epoch": 6.739679865206403,
      "grad_norm": 2.184739112854004,
      "learning_rate": 1.6314237573715248e-05,
      "loss": 5.0162,
      "step": 24000
    },
    {
      "epoch": 6.739679865206403,
      "eval_loss": 4.922755241394043,
      "eval_runtime": 41.8474,
      "eval_samples_per_second": 454.938,
      "eval_steps_per_second": 9.487,
      "step": 24000
    },
    {
      "epoch": 7.020499859590003,
      "grad_norm": 2.1344237327575684,
      "learning_rate": 1.491013760179725e-05,
      "loss": 5.0004,
      "step": 25000
    },
    {
      "epoch": 7.020499859590003,
      "eval_loss": 4.905955791473389,
      "eval_runtime": 41.6268,
      "eval_samples_per_second": 457.35,
      "eval_steps_per_second": 9.537,
      "step": 25000
    },
    {
      "epoch": 7.301319853973603,
      "grad_norm": 2.127110481262207,
      "learning_rate": 1.3506037629879248e-05,
      "loss": 4.9813,
      "step": 26000
    },
    {
      "epoch": 7.301319853973603,
      "eval_loss": 4.894100189208984,
      "eval_runtime": 41.5996,
      "eval_samples_per_second": 457.648,
      "eval_steps_per_second": 9.543,
      "step": 26000
    },
    {
      "epoch": 7.582139848357203,
      "grad_norm": 2.247466564178467,
      "learning_rate": 1.2103341757933166e-05,
      "loss": 4.9739,
      "step": 27000
    },
    {
      "epoch": 7.582139848357203,
      "eval_loss": 4.8819074630737305,
      "eval_runtime": 41.6269,
      "eval_samples_per_second": 457.349,
      "eval_steps_per_second": 9.537,
      "step": 27000
    },
    {
      "epoch": 7.862959842740803,
      "grad_norm": 2.3003499507904053,
      "learning_rate": 1.0699241786015165e-05,
      "loss": 4.9641,
      "step": 28000
    },
    {
      "epoch": 7.862959842740803,
      "eval_loss": 4.872275352478027,
      "eval_runtime": 41.798,
      "eval_samples_per_second": 455.476,
      "eval_steps_per_second": 9.498,
      "step": 28000
    },
    {
      "epoch": 8.143779837124404,
      "grad_norm": 2.2937238216400146,
      "learning_rate": 9.295141814097163e-06,
      "loss": 4.9481,
      "step": 29000
    },
    {
      "epoch": 8.143779837124404,
      "eval_loss": 4.863448619842529,
      "eval_runtime": 41.4965,
      "eval_samples_per_second": 458.786,
      "eval_steps_per_second": 9.567,
      "step": 29000
    },
    {
      "epoch": 8.424599831508003,
      "grad_norm": 2.251582145690918,
      "learning_rate": 7.891041842179162e-06,
      "loss": 4.9425,
      "step": 30000
    },
    {
      "epoch": 8.424599831508003,
      "eval_loss": 4.855580806732178,
      "eval_runtime": 41.8498,
      "eval_samples_per_second": 454.912,
      "eval_steps_per_second": 9.486,
      "step": 30000
    },
    {
      "epoch": 8.705419825891603,
      "grad_norm": 2.2603485584259033,
      "learning_rate": 6.488345970233081e-06,
      "loss": 4.9344,
      "step": 31000
    },
    {
      "epoch": 8.705419825891603,
      "eval_loss": 4.8479814529418945,
      "eval_runtime": 41.7484,
      "eval_samples_per_second": 456.018,
      "eval_steps_per_second": 9.509,
      "step": 31000
    },
    {
      "epoch": 8.986239820275204,
      "grad_norm": 2.1654467582702637,
      "learning_rate": 5.084245998315081e-06,
      "loss": 4.9287,
      "step": 32000
    },
    {
      "epoch": 8.986239820275204,
      "eval_loss": 4.842626094818115,
      "eval_runtime": 41.4467,
      "eval_samples_per_second": 459.337,
      "eval_steps_per_second": 9.579,
      "step": 32000
    },
    {
      "epoch": 9.267059814658804,
      "grad_norm": 2.2971420288085938,
      "learning_rate": 3.6815501263689974e-06,
      "loss": 4.9236,
      "step": 33000
    },
    {
      "epoch": 9.267059814658804,
      "eval_loss": 4.837663173675537,
      "eval_runtime": 42.092,
      "eval_samples_per_second": 452.295,
      "eval_steps_per_second": 9.432,
      "step": 33000
    },
    {
      "epoch": 9.547879809042405,
      "grad_norm": 2.3674139976501465,
      "learning_rate": 2.277450154450997e-06,
      "loss": 4.9164,
      "step": 34000
    },
    {
      "epoch": 9.547879809042405,
      "eval_loss": 4.834923267364502,
      "eval_runtime": 42.5409,
      "eval_samples_per_second": 447.522,
      "eval_steps_per_second": 9.332,
      "step": 34000
    },
    {
      "epoch": 9.828699803426003,
      "grad_norm": 2.325037956237793,
      "learning_rate": 8.747542825049145e-07,
      "loss": 4.9153,
      "step": 35000
    },
    {
      "epoch": 9.828699803426003,
      "eval_loss": 4.832523345947266,
      "eval_runtime": 42.0209,
      "eval_samples_per_second": 453.061,
      "eval_steps_per_second": 9.448,
      "step": 35000
    }
  ],
  "logging_steps": 1000,
  "max_steps": 35610,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.222678756196352e+16,
  "train_batch_size": 48,
  "trial_name": null,
  "trial_params": null
}
