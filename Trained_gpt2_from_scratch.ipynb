{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ab8c32",
   "metadata": {
    "id": "77ab8c32"
   },
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "-_A_Qu3R367e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19633,
     "status": "ok",
     "timestamp": 1752478779155,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "-_A_Qu3R367e",
    "outputId": "130e9661-14ff-418c-b8e2-f99749ca0dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oxnSQy5RbI4h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16386,
     "status": "ok",
     "timestamp": 1752478752095,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "oxnSQy5RbI4h",
    "outputId": "bccb8e33-daef-4912-83ab-f916fd32e663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.0.0 fsspec-2025.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09597fbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "184c0c3fa82145e79159ff285793393e",
      "bbc790e4a0204145928451ed88f8e6b3",
      "2c5129a05b1c49f6881440f9385a7f97",
      "bac5dce1cfbe424da811d1b4f151ba60",
      "2c45671b3fbd456ca32477067fc13d39",
      "32096ae590ab4d28a0907fb8bdd28a89",
      "2b75332c0d57443db241c9a512cc9a9b",
      "dcdabdb08c7e4ff2b33078df5f992437",
      "c4ff4cb6c2614c17a544953941f85e6c",
      "11b3a91823634643be1f77f3802abfd0",
      "13baeb6d866048569b5e0b6a10f43abc",
      "fa2864d150e243328c2c844346608277",
      "53d5ccfb1c674553a0021b21e04eb6e5",
      "e47d53836b3c41fb8396561102ad14f0",
      "03e91cd95e1c4d91a43d9b1e75a5c165",
      "9f1b3c118e4b4ef2bfdf1fe2ae72119e",
      "82ce1590ef38453980f10216b5387948",
      "73b98bc0220d4c62abf4007708368d78",
      "2fc37affb22b4ce9a49a8a25b96f4d1d",
      "46a244d6e6094df6a67c77db1c6eeb97",
      "2857188c26b04cde8971fac7cfe237e2",
      "c1a6f09173674ab3868d178f25d97db8",
      "117f07d9be1e4c6aa0406e95f412086a",
      "2c7335ca76184a619c5c8a5827385eaf",
      "3da55e8dd0fd4b2480a708a002eacbf8",
      "1229741e5ff44f48a8fe2e27872bf0ba",
      "d3792f3748cf4cccb61dc00bb6d229f8",
      "af6bf1538a614b07ba5122bf61ac3cae",
      "5aeadc99253c4ccbb5a919c70cf156c6",
      "e261cbe39bd849ecb11d67115d09ff76",
      "782c4c8bf2a44eb7a33896e08b10c5cc",
      "be7d443ef699408596891a678b3501b2",
      "ec702d8ee1904697a9d83b004c554f84"
     ]
    },
    "executionInfo": {
     "elapsed": 6822,
     "status": "ok",
     "timestamp": 1752478814499,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "09597fbc",
    "outputId": "8e06f2bf-39db-40c7-b963-41f5d2339d28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184c0c3fa82145e79159ff285793393e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2864d150e243328c2c844346608277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-091e566583af27e4.parquet:   0%|          | 0.00/141M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117f07d9be1e4c6aa0406e95f412086a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"datablations/c4-filter-small\", split=\"train\")\n",
    "ds = ds.select_columns([\"text\"])\n",
    "ds = ds.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0899812",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1752478815383,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "f0899812",
    "outputId": "76d703f3-bf36-41cc-bffb-03fed1c1ebc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8625a",
   "metadata": {
    "id": "f7b8625a"
   },
   "source": [
    "## **Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ae475",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97196,
     "status": "ok",
     "timestamp": 1752478935179,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "fc4ae475",
    "outputId": "f4fdadb0-22a5-4625-f1b5-fc71815a1ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ĠI', 'Ġam', 'Ġlearning', 'ĠGP', 'T', 'Ġtoken', 'izer']\n",
      "[259, 611, 2292, 11887, 55, 17992, 6240]\n",
      " I am learning GPT tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from tokenizers.normalizers import NFKC\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "\n",
    "# Initialize BPE token\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = ByteLevel()\n",
    "tokenizer.normalizer = NFKC()\n",
    "tokenizer.decoder = ByteLevelDecoder()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=20000,\n",
    "    special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(ds[\"train\"][\"text\"], trainer)\n",
    "tokenizer.save(\"/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt_tokenizer.json\")\n",
    "\n",
    "# test\n",
    "output = tokenizer.encode(\"I am learning GPT tokenizer\")\n",
    "print(output.tokens)   # token/subword\n",
    "print(output.ids)      # ID token\n",
    "print(tokenizer.decode(output.ids))  # decode text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed411e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5137,
     "status": "ok",
     "timestamp": 1752478952486,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "2ed411e9",
    "outputId": "f38b466d-6f39-4427-abbd-d46dcc00feff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt-tokenizer/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt-tokenizer/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt-tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt_tokenizer.json\")\n",
    "tokenizer.add_special_tokens({\n",
    "    \"bos_token\": \"<s>\",\n",
    "    \"eos_token\": \"</s>\",\n",
    "    \"unk_token\": \"<unk>\",\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"mask_token\": \"<mask>\",\n",
    "})\n",
    "\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8f46c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752478965884,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "de8f46c4",
    "outputId": "a3d01dd9-bbcd-4ed5-8a83-97e3ccf13149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e46ffe2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1752478974425,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "1e46ffe2",
    "outputId": "9f585b24-95a4-4068-9954-d1ac5934cf45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id, tokenizer.eos_token_id, tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4ad92a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c50dc8cc4e5743cfb14f8930b94f7c70",
      "9799e0793bad4d31949d00a8de73c5ee",
      "629df96a9f2f409d9195d9bfba963ac5",
      "288029429dd849fdb6fd5f0485281728",
      "007897c807334ac4918417dbf2362f4a",
      "2e65371d6dbd45279a2ac2c49d2a36c5",
      "9adad560111c43b4914caa39ecd674e9",
      "1a2807dec3a2464d95de1be052f3ea3c",
      "9d8e8d551b704a5db385649958ca3b6b",
      "6946805f8def4e7d81db09a499211bfa",
      "518b8374e64b411f9befe633b1ebd2ea",
      "5685f696befc490dbe9b6824b8de0bf2",
      "a621888883e44821babde5f0c54c60c0",
      "cdb2e213490940c9b30f0ec0adb1a9df",
      "e96a719a122042bfb1e8d8546209563f",
      "be3c72f082b449b69adbacd8bc5bff20",
      "9ef66406083c48688925b696e2fde4b9",
      "7938b4a644db47db8ab5f881fa1eebe5",
      "3c0a5151e5c842abbb3832d02d94252c",
      "3caef0f5cba84c1693a17298e492c4b8",
      "e6f1ef4a1883448a9acb3dbfb89499a2",
      "9e10c6e4c9d04fb8b975225a818f8e7c"
     ]
    },
    "executionInfo": {
     "elapsed": 203334,
     "status": "ok",
     "timestamp": 1752479179031,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "6b4ad92a",
    "outputId": "c3dc1bfb-a3ad-4603-c0fb-9c72b9b1981f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50dc8cc4e5743cfb14f8930b94f7c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5685f696befc490dbe9b6824b8de0bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"])\n",
    "\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize, remove_columns=[\"text\"], batched=True, num_proc=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc52f0d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752479190449,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "fc52f0d5",
    "outputId": "43107f3f-7547-4c12-db2a-3c98c761de7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64dad2b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "1493656ada1b4de7877fa6934871caf1",
      "0a12dcb4b7e249348acbed3fbc9db65c",
      "c36bfd7eea5a4de2b1691bf9035cffd4",
      "8c3097695c7847e8b7674e6898dc0fdf",
      "2913f9e133b94b288bf1caa0eea300d9",
      "08920f08e242418991480738427c1f60",
      "6406333d6db84d99939e9780c858784d",
      "7160c2d12fe04b10a26fefe76779500e",
      "3c2ad8dab80f4f7faaa218f51c7d7aa6",
      "764d8971b6bd4d19923dd3ab85ba94c9",
      "e981eeab791d43de88d8c22aafb03c68",
      "47073d998c744d7e957c71a3f8d0345e",
      "b8b8e3106f4e4a218223b1619e9bd93e",
      "38b085872dab47da9a5dd66888d72f5b",
      "bff8ad17db3a48a6b7fe10726e01a317",
      "31c63c1fd1bc4ac29b32d10974c334c0",
      "3bfe006974ce4899b045869275c39077",
      "0e438308c76647dea07e0c4e1ba83e78",
      "f1e473490e854f678131cb4193c7f2ec",
      "b8b06b7223504111bc45811d811c710a",
      "b69c2bd7c7e7437cac6cd3a27cd92cd5",
      "a31840aa91c445198580e485b53ac961"
     ]
    },
    "executionInfo": {
     "elapsed": 331145,
     "status": "ok",
     "timestamp": 1752479531916,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "64dad2b9",
    "outputId": "a3fa9339-13b9-47f3-d299-227b27bb7ec4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1493656ada1b4de7877fa6934871caf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47073d998c744d7e957c71a3f8d0345e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=20):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = 256\n",
    "\n",
    "def group_texts(examples):\n",
    "    # concat input_ids\n",
    "    concatenated = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated[\"input_ids\"])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "\n",
    "    # split block_size\n",
    "    result = {\n",
    "        k: [concatenated[k][i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k in concatenated\n",
    "    }\n",
    "\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_ds = tokenized_ds.map(group_texts, batched=True, num_proc=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ebbd12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1752479536463,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "47ebbd12",
    "outputId": "eff500b3-bf8a-4148-9007-34b8266e17db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170893\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 19038\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "badeccb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1752479539945,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "badeccb4",
    "outputId": "2f03dfdb-2130-4eeb-9cdf-268de0f1d90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51, 3701, 12, 87, 344, 5014, 472, 411, 13, 294, 10307, 253, 287, 1348, 16643, 411, 434, 2669, 13352, 8058, 2915, 1996, 234, 638, 1301, 675, 219, 3036, 10232, 3203, 269, 1131, 4881, 2492, 18, 1608, 16, 304, 6283, 327, 19, 47, 76, 10096, 12866, 214, 339, 832, 289, 241, 3445, 17, 2173, 415, 844, 4860, 16, 269, 1713, 16, 294, 2489, 234, 3735, 74, 531, 5256, 231, 18, 2249, 210, 16, 302, 914, 291, 676, 209, 4529, 241, 483, 17, 390, 747, 17, 14791, 16, 1579, 210, 6250, 3972, 17, 7638, 16327, 53, 4545, 968, 12566, 16, 4831, 4979, 1594, 16, 9906, 7666, 1972, 286, 433, 6369, 3226, 16, 238, 304, 3178, 1541, 274, 1835, 17, 3997, 4579, 5680, 5105, 16, 299, 267, 3862, 1501, 234, 8457, 214, 327, 19, 47, 76, 3290, 4637, 18, 441, 933, 13496, 356, 16, 483, 18735, 338, 245, 267, 5600, 234, 209, 9560, 2793, 19405, 338, 245, 16, 972, 209, 1321, 483, 305, 1179, 680, 209, 1250, 5014, 5007, 18, 300, 747, 253, 287, 1348, 173, 489, 1252, 933, 13496, 356, 311, 12385, 1080, 747, 19405, 338, 3441, 241, 12324, 231, 1250, 5014, 10505, 18, 300, 11231, 19825, 1374, 13644, 2977, 6127, 2585, 3950, 12597, 1227, 241, 214, 7284, 238, 2050, 235, 542, 3490, 650, 241, 214, 1072, 17, 173, 489, 338, 209, 591, 211, 1276, 3631, 1688, 345, 261, 80, 18, 12168, 16, 214, 2914, 3445, 15093, 86, 234, 1685, 1246, 306, 20, 12, 20, 13, 20, 12, 20, 13, 20, 12, 20, 661, 441, 373, 757, 16], [302, 7877, 291, 16, 240, 1741, 16, 214, 1870, 17, 15438, 4301, 1113, 269, 3319, 944, 2068, 240, 339, 832, 695, 214, 1139, 3445, 241, 306, 13681, 19, 47, 76, 7532, 18, 12687, 285, 16, 11480, 308, 1521, 1689, 376, 18, 414, 54, 17183, 214, 11711, 11767, 238, 15610, 1348, 18249, 4637, 241, 9159, 12, 87, 344, 5014, 472, 411, 13, 19, 47, 76, 7532, 5210, 16327, 53, 9092, 19910, 3226, 1090, 16308, 437, 271, 3543, 5592, 279, 18, 237, 370, 692, 4445, 2644, 17, 4113, 18, 48, 712, 4909, 269, 214, 297, 597, 243, 345, 865, 18, 526, 800, 2053, 375, 39, 20, 16, 375, 39, 20, 16, 375, 39, 237, 16, 238, 375, 39, 237, 333, 1777, 310, 16, 4865, 345, 19, 20, 16, 345, 19, 20, 16, 345, 19, 237, 16, 238, 345, 19, 237, 241, 16291, 1284, 676, 7573, 16, 5878, 234, 345, 19, 20, 19, 20, 19, 20, 17, 11140, 10237, 18, 271, 6303, 10620, 17, 77, 1682, 818, 8553, 209, 4943, 2244, 238, 8548, 8573, 1159, 5383, 18, 6861, 5918, 2132, 1115, 262, 466, 6361, 240, 12258, 209, 10821, 352, 238, 5311, 319, 16, 3040, 262, 466, 6321, 5040, 269, 334, 6007, 18, 51, 11394, 560, 2906, 6518, 345, 80, 2554, 345, 80, 264, 8056, 1489, 267, 209, 1188, 454, 2568, 269, 916, 8315, 234, 2340, 467, 4674, 338, 2207, 18, 526, 4251, 2053, 214, 4241, 7117, 345, 91, 20, 80, 4980, 30, 2906, 6518, 3980, 30, 345, 91, 345, 80, 238, 345, 91, 345, 80, 5770, 6518, 274, 483], [1556, 370, 1026, 411, 320, 2394, 6097, 5503, 233, 3164, 238, 209, 800, 241, 17456, 238, 596, 2028, 18, 363, 8056, 1489, 6859, 361, 1553, 309, 830, 309, 262, 550, 240, 2653, 241, 4253, 16, 2090, 238, 16719, 309, 214, 1044, 3980, 238, 5468, 530, 676, 214, 9275, 7390, 241, 610, 830, 6859, 267, 2828, 18, 526, 361, 1553, 955, 7562, 238, 4253, 9104, 1051, 10657, 60, 46, 238, 13130, 464, 9104, 7124, 18, 5210, 18946, 947, 3015, 289, 6859, 1595, 291, 334, 9394, 238, 12535, 267, 1817, 3713, 286, 1185, 240, 214, 4584, 18, 7674, 231, 274, 234, 209, 2605, 2282, 4584, 302, 1817, 2091, 214, 3546, 294, 334, 15735, 238, 9394, 269, 9346, 10737, 18, 526, 1595, 214, 12535, 434, 209, 6061, 10737, 502, 383, 385, 12658, 16, 7237, 320, 19551, 294, 2362, 320, 9461, 643, 18, 5210, 18946, 947, 3015, 289, 6859, 1595, 291, 933, 4597, 361, 359, 299, 322, 788, 818, 238, 361, 9286, 334, 2504, 4253, 7124, 234, 2827, 334, 1281, 12535, 18, 300, 1556, 90, 5170, 361, 270, 6518, 274, 2118, 214, 2494, 320, 214, 2394, 241, 214, 2184, 2223, 214, 1556, 291, 267, 494, 7963, 233, 383, 270, 15048, 3337, 2282, 17, 309, 209, 1124, 241, 1051, 209, 2605, 2282, 4584, 18, 1123, 1358, 551, 3245, 5363, 238, 4141, 551, 5982, 262, 361, 956, 240, 456, 2024, 6520, 18, 3871, 2999, 294, 334, 17275, 264, 8056, 1489, 383, 270, 214, 11077, 8081, 87, 560, 4241, 7117, 264, 8056, 1489, 4980, 18, 526, 4980, 267, 904, 241, 345, 3235, 4922], [17323, 2336, 214, 3445, 238, 267, 4120, 294, 279, 3235, 5036, 19184, 6996, 16, 279, 91, 237, 3235, 3980, 7869, 238, 4250, 12500, 2336, 18, 1401, 8717, 233, 7869, 383, 385, 17144, 698, 3292, 238, 214, 4250, 12500, 311, 214, 1098, 16271, 5486, 309, 477, 12889, 214, 17276, 369, 2050, 235, 4412, 18, 300, 345, 91, 20, 80, 4980, 19768, 279, 12503, 238, 4717, 86, 820, 234, 209, 1980, 241, 532, 8194, 2554, 279, 8194, 2554, 279, 8194, 18, 300, 4814, 1086, 225, 311, 4332, 16168, 502, 2549, 269, 2133, 14283, 2637, 18, 8560, 1363, 411, 1118, 6605, 311, 517, 698, 409, 14055, 9144, 269, 3293, 1116, 1407, 457, 18, 6993, 765, 457, 214, 11764, 267, 341, 86, 4691, 294, 747, 671, 448, 361, 270, 1621, 386, 483, 874, 18, 625, 361, 5834, 334, 9394, 234, 368, 386, 1051, 456, 11764, 8736, 18, 651, 262, 311, 6444, 234, 1417, 334, 9394, 262, 361, 2304, 368, 334, 15735, 1478, 294, 209, 5945, 241, 599, 262, 600, 550, 234, 2441, 35, 83, 11394, 560, 18, 14525, 5183, 231, 334, 1255, 1156, 18, 504, 383, 1154, 2304, 262, 209, 19917, 457, 269, 10885, 906, 6859, 18, 7674, 231, 383, 781, 860, 4825, 345, 2557, 906, 3309, 18, 651, 262, 567, 334, 6518, 264, 8056, 1489, 1252, 373, 524, 4980, 1872, 1482, 368, 772, 302, 383, 270, 1199, 234, 9269, 18, 9347, 1167, 1780, 813, 2420, 240, 214, 6930, 264, 462, 12044, 11865, 905, 9630, 10786, 5010, 241, 16789, 9046, 338, 214, 4514, 375, 4481, 7845, 18, 625, 361, 1481], [209, 2452, 241, 9408, 16, 816, 309, 209, 12010, 6493, 1443, 16, 345, 17, 15348, 3505, 3599, 294, 305, 3357, 16, 11780, 238, 4574, 16, 561, 1165, 15140, 3505, 3599, 294, 6313, 2919, 238, 9042, 1326, 16, 1655, 12428, 1146, 483, 294, 304, 18120, 360, 387, 221, 72, 343, 16, 10720, 238, 9607, 8879, 16, 3857, 13506, 238, 4287, 17, 11538, 2665, 2865, 1824, 238, 214, 16789, 9046, 15746, 2206, 1252, 214, 1573, 18, 526, 257, 804, 14165, 345, 17, 15348, 813, 294, 345, 8115, 16, 345, 18, 20, 17884, 238, 345, 807, 6548, 16, 8327, 623, 209, 226, 861, 215, 291, 434, 1296, 4093, 234, 214, 6493, 3120, 238, 234, 334, 8301, 3857, 8886, 18, 300, 9294, 264, 17710, 2819, 238, 9135, 4367, 9772, 16, 1809, 209, 1394, 2919, 5646, 294, 4093, 16141, 214, 752, 1326, 238, 342, 319, 5722, 18, 300, 3693, 3767, 267, 2420, 274, 214, 1321, 2994, 294, 747, 2481, 17, 210, 2786, 1075, 238, 7823, 4664, 700, 18, 1751, 8489, 8578, 311, 517, 2420, 457, 13432, 238, 311, 10666, 386, 209, 14350, 16, 238, 10889, 1251, 18, 2160, 1867, 234, 4183, 905, 4574, 1992, 16, 238, 234, 214, 12219, 5294, 2640, 16, 214, 1474, 5583, 257, 7107, 3787, 16, 12997, 2917, 8350, 16, 7600, 16, 238, 234, 214, 10351, 10203, 18, 9913, 709, 1402, 503, 9480, 86, 2339, 269, 262, 5, 5946, 457, 234, 1358, 992, 6499, 238, 1544, 2147, 269, 2644, 5992, 6895, 16936, 18, 12997, 267, 2420, 240, 3831, 18, 12997, 16, 3831, 2644, 434, 209, 4097, 241, 532]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   51,  3701,    12,  ...,   373,   757,    16],\n",
       "        [  302,  7877,   291,  ...,  6518,   274,   483],\n",
       "        [ 1556,   370,  1026,  ...,   345,  3235,  4922],\n",
       "        [17323,  2336,   214,  ...,   625,   361,  1481],\n",
       "        [  209,  2452,   241,  ...,  4097,   241,   532]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lm_ds[\"train\"][\"input_ids\"][:5])\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.tensor(lm_ds[\"train\"][\"input_ids\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d062862d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1752479542048,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "d062862d",
    "outputId": "ad6a8cc0-0879-4903-99e5-46f69414fa22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170893\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 19038\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5836f0",
   "metadata": {
    "id": "8c5836f0"
   },
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76bfa511",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19366,
     "status": "ok",
     "timestamp": 1752479568571,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "76bfa511",
    "outputId": "1fe14082-37e1-4088-f334-f4d793a17e4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20000, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=block_size,\n",
    "    n_ctx=block_size,\n",
    "    n_embd=256,\n",
    "    n_layer=6,\n",
    "    n_head=4,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model.resize_token_embeddings(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5541b8cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 29185,
     "status": "ok",
     "timestamp": 1752479609419,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "5541b8cb",
    "outputId": "dd0f6511-16c0-4707-b87a-631beb48280f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manhnguyentien8365\u001b[0m (\u001b[33manhnguyentien8365-no\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250714_075330-31e1rrv7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining/runs/31e1rrv7' target=\"_blank\">c4-en-small</a></strong> to <a href='https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining' target=\"_blank\">https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining/runs/31e1rrv7' target=\"_blank\">https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining/runs/31e1rrv7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/anhnguyentien8365-no/gpt2-pretraining/runs/31e1rrv7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7b0e107fc910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use wandb\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"gpt2-pretraining\",\n",
    "    name=\"c4-en-small\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93137244",
   "metadata": {
    "executionInfo": {
     "elapsed": 2346,
     "status": "ok",
     "timestamp": 1752479728145,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "93137244"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/gpt-small-c4\",\n",
    "    logging_dir=\"/content/drive/MyDrive/Colab Notebooks/Train_gpt2_from_scrath/logs\",\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=48,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    logging_steps=1000,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_ds[\"train\"],\n",
    "    eval_dataset=lm_ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1fc050",
   "metadata": {
    "id": "de1fc050"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34705b95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9196223,
     "status": "ok",
     "timestamp": 1752488931422,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "34705b95",
    "outputId": "6c922663-17d4-4714-b68a-c0c33ca30ff8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35610' max='35610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35610/35610 2:33:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.270700</td>\n",
       "      <td>6.605732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.428700</td>\n",
       "      <td>6.248656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.166000</td>\n",
       "      <td>6.034111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.989700</td>\n",
       "      <td>5.881382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.860800</td>\n",
       "      <td>5.765547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.758600</td>\n",
       "      <td>5.661932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.672100</td>\n",
       "      <td>5.577486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.588800</td>\n",
       "      <td>5.505172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>5.527900</td>\n",
       "      <td>5.441109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>5.468000</td>\n",
       "      <td>5.384087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>5.414200</td>\n",
       "      <td>5.331681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>5.367100</td>\n",
       "      <td>5.283950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>5.322900</td>\n",
       "      <td>5.242126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>5.285900</td>\n",
       "      <td>5.200370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>5.242200</td>\n",
       "      <td>5.161082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>5.210100</td>\n",
       "      <td>5.123721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>5.183100</td>\n",
       "      <td>5.091982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>5.150800</td>\n",
       "      <td>5.060781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>5.118200</td>\n",
       "      <td>5.031572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>5.097500</td>\n",
       "      <td>5.003676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>5.078700</td>\n",
       "      <td>4.981496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>5.049300</td>\n",
       "      <td>4.959826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>5.032300</td>\n",
       "      <td>4.940311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>5.016200</td>\n",
       "      <td>4.922755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>5.000400</td>\n",
       "      <td>4.905956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>4.981300</td>\n",
       "      <td>4.894100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>4.973900</td>\n",
       "      <td>4.881907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>4.964100</td>\n",
       "      <td>4.872275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>4.948100</td>\n",
       "      <td>4.863449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>4.942500</td>\n",
       "      <td>4.855581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>4.934400</td>\n",
       "      <td>4.847981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>4.928700</td>\n",
       "      <td>4.842626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>4.923600</td>\n",
       "      <td>4.837663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>4.916400</td>\n",
       "      <td>4.834923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>4.915300</td>\n",
       "      <td>4.832523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35610, training_loss=5.327908358618102, metrics={'train_runtime': 9195.9715, 'train_samples_per_second': 185.835, 'train_steps_per_second': 3.872, 'total_flos': 1.243966819270656e+16, 'train_loss': 5.327908358618102, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a1941d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758,
     "referenced_widgets": [
      "57a2e2baafaa421a8f3125271e3e58ea",
      "2d96f4c89a174d5f8ced1f04bb4a7e10",
      "799ffdb4a0e8420fba347fc931441288",
      "a0bb3b43b39b4d07bd02031550795e13",
      "0c28493e6b894b6b9457348a71fcbe0f",
      "62600cadf1cd44b49dafa09474395367",
      "5a1be8cbfa07422faa9b36b018b1bf93",
      "94eb53fea8a6434e836cbe8944682eb5",
      "50dd8a5c7a9a41bfb615ceaa9782a20f",
      "7fe0cdf48729458b8824c291e227db7f",
      "82348498ec1446e4a191e7814e251ae9",
      "e0205022f6ae4f3a9b44246e01e6d617",
      "61c645e1ce3c4d4485513cc2a685af0c",
      "698ca05b0f6a4d18a5c636976c25cae1",
      "8da87cd8a0524211be5844bebb782ef7",
      "bf06c7809ff747f698ec63494c16fe63",
      "fc0291b0ce5a41eeb36e39c60153efc0",
      "d26d4e5694d5440997f57b3ebd078be7",
      "ad9cf98df69b47e3a40ca4d8578b15d9",
      "90847af02ed6418aa367dbb0ca0475da",
      "63c31a8543694197aa392378149ce21a",
      "8873f19dac6b4ec3afa0f8650e659ce3"
     ]
    },
    "executionInfo": {
     "elapsed": 25173,
     "status": "ok",
     "timestamp": 1752488962144,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "9a1941d0",
    "outputId": "ae20e9fd-212d-4b38-9f1d-bd37ccf78356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.7.9)\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): \n",
      "Add token as git credential? (Y/n) Y\n",
      "Token is valid (permission: write).\n",
      "The token `NTA1802/Trained-GPT2-from-scratch` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `NTA1802/Trained-GPT2-from-scratch`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a2e2baafaa421a8f3125271e3e58ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/39.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0205022f6ae4f3a9b44246e01e6d617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/NTA1802/Trained-GPT2-from-scratch/commit/44d35173a477419af041f5d235e81426a4d0a8ab', commit_message='Upload tokenizer', commit_description='', oid='44d35173a477419af041f5d235e81426a4d0a8ab', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NTA1802/Trained-GPT2-from-scratch', endpoint='https://huggingface.co', repo_type='model', repo_id='NTA1802/Trained-GPT2-from-scratch'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!huggingface-cli login\n",
    "\n",
    "\n",
    "model.push_to_hub(\"NTA1802/Trained-GPT2-from-scratch\")\n",
    "tokenizer.push_to_hub(\"NTA1802/Trained-GPT2-from-scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb85ca8",
   "metadata": {
    "id": "8eb85ca8"
   },
   "source": [
    "## **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d399868",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "a767715a346d4929988cf83d7a92fe9e",
      "f2b4876d1de549918ae71ec287aac6ec",
      "e867e0182bcc40e69005d854be5cb394",
      "14b1bc2a17604d68ad61323f03192e19",
      "d62170c6720d42bea41c49029597d916",
      "1d1481bfc96b45e69a99c34226aa3eb6",
      "a197a2c7460f415eb5d809dcbd621d83",
      "07c08a5d8af849b8a5eaaf207af5475a",
      "e4e629d16822405292d54c4db5305e83",
      "e295178da1734f5babcbed1c2f885e62",
      "db7450e92c614f47b9f03b543166919f",
      "7878ba537c6647268de33b55f070d25d",
      "f9358dcddd464a58883be569519709fc",
      "fc617508100744a19d7182b49452e971",
      "f4c4d5e757b743f9a401ded6a675750c",
      "ee03e7ed254f438ba98b07c0366ed7bf",
      "bcbcda56fdd74425b2c2c4e8f2f46947",
      "7105b7c5dc4141adbf418ab5cebaa59e",
      "f4024f3f0c4142c29ac7ea2ed521e1a7",
      "c323c18fefa44e17b98db4a606ffdc03",
      "25c897f3d74243d88fd723106a8a242f",
      "f5ee62f64e3d478ab2e4ae00a60146b5",
      "f3df998bed2648169c656427971932b7",
      "87ca84d35fbf47e3b81c1d7d16c87ff3",
      "4bd0fabff02d4c779d3d8a42a52d563a",
      "58855c7aaf08457891233bbef24203dc",
      "cfb19009489a4dd2b2b880b90cc85780",
      "56e4debcc33a4e6eacc474b61bc9e5c7",
      "73861558e48046fbabf14e610e1366ba",
      "1e1809fdb79340deb75c4abd5bd494ee",
      "3546d63aab69406eaafa14d80a3b9db7",
      "bb4fa322732c43c88a7b9dc2d8fc98d3",
      "4277629e0b704e638d9aa463b4fc6940",
      "adbf4cf0266b45f090d4892b0da9b1bd",
      "2ba05ee849694fc5b96ddb9e325f5812",
      "6de2d5affef940c8b10d75128182e106",
      "1da840910e1e412dae35b6512930c701",
      "838b3fc510ca4b2f98ea3b3836b030d8",
      "136584099263405d88414213305eadcb",
      "10cc09e34b13454f9833d788c7beaee3",
      "f41c91d64ccd45b8a3e3e7b35f897b87",
      "bfebbeff8e514fc485de763b7bdb30ed",
      "d8b54c621f1b4fc7b74693caa9514fc9",
      "f09d20fdd2bf4b1fb950d4b614943abe",
      "8dab5bbcaeb644db8dc15b0c51acaf80",
      "f119f886cd1d418a80b2b763767a9497",
      "a56b7aa1c9e74eaa9d697df7020fce71",
      "30a3513322494fa79be148144ac11f19",
      "02779546a6614ca9946e9b96129dc7f8",
      "af0f41bb1b0f41cd8ff06f03b54e59af",
      "04674618c61a484d9e8aaae801374f48",
      "c941bcbc81fc4766ba6c4efabd0896f2",
      "680821b0f97c494aa224ccf96a23bd75",
      "dfbc8c63962d4beeaa5410090b2ce06f",
      "b53746baa2a44f3c9b0cb19329a34180",
      "eae451ab234b4669965e66944194c3ec",
      "24b842458d0843998da26108401a68f2",
      "f3b0518ed5fc45b9b4022860fd392fbb",
      "2c334f6854b14f94ade25828c183a1a8",
      "decffc44549348b0b1fecd93bcc7926d",
      "06990eff9f9c4918aeae9fb441320714",
      "1bed328ebd1941069491a6453dbbe1dc",
      "49f6c6d46f25465eaa0dfbe2eeee6f2d",
      "aa1cf2077a0b4b5193f438675f283f1b",
      "ba02c19f8e244084b248da19f4e21584",
      "a29e2999dfd24058820e15a797a9bf9e"
     ]
    },
    "executionInfo": {
     "elapsed": 9982,
     "status": "ok",
     "timestamp": 1752488981386,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "4d399868",
    "outputId": "e45bbb7e-9170-4df4-abec-823ff752cc5d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a767715a346d4929988cf83d7a92fe9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/756 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7878ba537c6647268de33b55f070d25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/39.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3df998bed2648169c656427971932b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbf4cf0266b45f090d4892b0da9b1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dab5bbcaeb644db8dc15b0c51acaf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae451ab234b4669965e66944194c3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/692 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"NTA1802/Trained-GPT2-from-scratch\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2412442",
   "metadata": {
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1752489060142,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "a2412442"
   },
   "outputs": [],
   "source": [
    "prompt = \"Today is a very good day\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b1d9bd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1752489061892,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "0b1d9bd9",
    "outputId": "bceaeefc-56bc-4f6e-955a-6ab037129063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is a very good day, we were able to see a good deal to be able to start on the market, we decided to do that because the business is very small. As my parents and families, I would make these things more affordable when we could help them to avoid\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8688ed0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1752489100615,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "8688ed0f",
    "outputId": "412e0e3b-2cca-4a10-9c51-8d38adc00c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.295598012486877"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Shift for labels (causal LM setting: predict token t+1 from token t)\n",
    "labels = output[:, 1:].clone()\n",
    "inputs = output[:, :-1].clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Compute log softmax over vocabulary\n",
    "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "\n",
    "# Gather log-probabilities corresponding to the labels\n",
    "selected_log_probs = log_probs.gather(2, labels.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "# Sum negative log probs → total NLL\n",
    "nll = -selected_log_probs.sum().item()\n",
    "num_tokens = labels.numel()\n",
    "perplexity = math.exp(nll / num_tokens)\n",
    "perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e5dd0f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1752489106745,
     "user": {
      "displayName": "Tiến Anh Nguyễn",
      "userId": "17210799405645199378"
     },
     "user_tz": -420
    },
    "id": "8e5dd0f1",
    "outputId": "f2f43fd1-9a8d-4b82-ee4f-eb6b02801117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA cache cleared.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA cache cleared.\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
